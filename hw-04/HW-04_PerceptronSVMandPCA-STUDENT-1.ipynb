{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework Assignment 4\n",
    "\n",
    "## Using the Perceptron, SVMs, and PCA with Credit Card Approval Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <p style=\"text-align: right;\"> &#9989; Molly Scherer</p>\n",
    "### <p style=\"text-align: right;\"> &#9989; schererm</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://storage.googleapis.com/kaggle-datasets-images/3807174/6598147/ab3c96d720559e8bff08d02bd035f93c/dataset-cover.jpg?t=2023-10-03-01-37-20\" width=400px align=\"right\" style=\"margin-left: 20px\" alt=\"Underwater naval mines\">\n",
    "\n",
    "### Goals for this homework assignment\n",
    "\n",
    "By the end of this assignment, you should be able to:\n",
    "* Use `git` and the branching functionality to track your work and turn in your assignment\n",
    "* Read in data and prepare it for modeling\n",
    "* Build, fit, and evaluate an SVC model of data\n",
    "* Use PCA to reduce the number of important features\n",
    "* Build, fit, and evaluate an SVC model of PCA-transformed data\n",
    "* Train a perceptron and compare to SVC model\n",
    "\n",
    "### Assignment instructions:\n",
    "\n",
    "Work through the following assignment, making sure to follow all of the directions and answer all of the questions.\n",
    "\n",
    "There are **62 points** possible on this assignment. Point values for each part are included in the section headers.\n",
    "\n",
    "This assignment is **due by 11:59 pm on Friday, April 12. It should be pushed to your repo (see Part 1) AND submitted to D2L**. \n",
    "\n",
    "#### Imports\n",
    "\n",
    "It's useful to put all of the imports you need for this assignment in one place. Read through the assignment to figure out which imports you'll need or add them here as you go."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put all necessary imports here\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import Perceptron"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 1: Git Repo Management and Branching (6 points)\n",
    "\n",
    "For this assignment, you're going to add it to the `cmse202-s24-turnin` repository you created in class so that you can track your progress on the assignment and preserve the final version that you turn in. In order to do this you need to\n",
    "\n",
    "**&#9989; Do the following**:\n",
    "\n",
    "1. Navigate to your `cmse202-s24-turnin` **local** repository and create a new directory called `hw-04`\n",
    "\n",
    "2. Move this notebook into that **new directory** in your repository.\n",
    "\n",
    "3. Create a **new branch** called `hw04_branch`.\n",
    "\n",
    "4. \"Check out\" the new branch (so that you'll be working on that branch). \n",
    "\n",
    "5. Double check to make sure you are actually on that branch.\n",
    "\n",
    "6. Once you're certain you're working on your new branch, add this notebook to your repository, then make a commit and push it to GitHub. You may need to use `git push origin hw04_branch` to push your new branch to GitHub.\n",
    "\n",
    "Finally, &#9989; **Do this**: Before you move on, put the command that your instructor should run to clone your repository in the markdown cell below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```bash\n",
    "! git clone https://github.com/schererm/CMSE202-s24-turnin\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Important**: Double check you've added your Professor and your TA as collaborators to your \"turnin\" repository (you should have done this in the previous homework assignment).\n",
    "\n",
    "**Also important**: Make sure that the version of this notebook that you are working on is the same one that you just added to your repository! If you are working on a different copy of the notebook, **none of your changes will be tracked**!\n",
    "\n",
    "If everything went as intended, the file should now show up on your GitHub account in the \"`cmse202-s24-turnin`\" repository inside the `hw-04` directory that you just created within the new branch `hw04_branch`.\n",
    "\n",
    "Periodically, **you'll be asked to commit your changes to the repository and push them to the remote GitHub location**. Of course, you can always commit your changes more often than that, if you wish.  It can be good to get into a habit of committing your changes any time you make a significant modification, or when you stop working on the project for a bit.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a id=\"loading\"></a>\n",
    "## Part 2. Loading a the dataset: Credit card approval data (7 points)\n",
    "\n",
    "The dataset contains information about individuals and whether they were approved or rejected for a credit card application. You can think of this approval or rejection as **binary classification**.\n",
    "\n",
    "The goal of this assignment is to use this dataset to practice using the Perceptron classifier, SVMs, and PCA tools we've covered in class. Since the goal of the assignment is to develop models, we have done most of the pre-processing of the data for you (isolating numeric columns, rescaling the data with `StandardScalar`), with the exception of leaving it to you to remove some missing values as we have done in class. \n",
    " \n",
    "#### The data\n",
    "\n",
    "**&#9989; Do This:**  To get started, you'll need to download the associated `cc_data.csv` file:\n",
    "`https://raw.githubusercontent.com/yangy5/HWFiles/main/cc_data.csv`\n",
    "\n",
    "Once you've downloaded the data, **open the files using a text browser or other tool on your computer and take a look at the data to get a sense of the information it contains.** If you are curious about this dataset it came from the following link [CC Approval Data](https://www.kaggle.com/datasets/youssefaboelwafa/credit-card-approval/data)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Load the data\n",
    "\n",
    "**&#9989; Task 2.1 (2 point):** Read the ```cc_data.csv``` file into your notebook and drop the missing values. The missing values contain \"?\". We're going to use \"class\" column as the classes that we'll be trying to predict with our classification models.\n",
    "\n",
    "Once you've loaded in the data and dropped the missing data, **display the DataFrame to make sure it looks reasonable**. You should have **7 columns** and **666 rows**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100 86051  100 86051    0     0   592k      0 --:--:-- --:--:-- --:--:--  595k\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>var1</th>\n",
       "      <th>var2</th>\n",
       "      <th>var3</th>\n",
       "      <th>var4</th>\n",
       "      <th>var5</th>\n",
       "      <th>var6</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.06173102354640747</td>\n",
       "      <td>-0.955920</td>\n",
       "      <td>-0.290872</td>\n",
       "      <td>-0.287892</td>\n",
       "      <td>0.1034783002693444</td>\n",
       "      <td>-0.195272</td>\n",
       "      <td>+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.266444267315627</td>\n",
       "      <td>-0.060007</td>\n",
       "      <td>0.244013</td>\n",
       "      <td>0.740293</td>\n",
       "      <td>-0.8113307237034743</td>\n",
       "      <td>-0.087788</td>\n",
       "      <td>+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.5910898450678396</td>\n",
       "      <td>-0.855481</td>\n",
       "      <td>-0.216167</td>\n",
       "      <td>-0.493529</td>\n",
       "      <td>0.5522525384446895</td>\n",
       "      <td>-0.037117</td>\n",
       "      <td>+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.312611981613437</td>\n",
       "      <td>-0.646569</td>\n",
       "      <td>0.456175</td>\n",
       "      <td>0.534656</td>\n",
       "      <td>-0.48338031888302985</td>\n",
       "      <td>-0.194696</td>\n",
       "      <td>+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.9531946945445854</td>\n",
       "      <td>0.174015</td>\n",
       "      <td>-0.153415</td>\n",
       "      <td>-0.493529</td>\n",
       "      <td>-0.3683100014021721</td>\n",
       "      <td>-0.195272</td>\n",
       "      <td>+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>685</th>\n",
       "      <td>-0.8770941372642533</td>\n",
       "      <td>1.069928</td>\n",
       "      <td>-0.290872</td>\n",
       "      <td>-0.493529</td>\n",
       "      <td>0.43718222096383175</td>\n",
       "      <td>-0.195272</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>686</th>\n",
       "      <td>-0.7441272294887274</td>\n",
       "      <td>-0.805262</td>\n",
       "      <td>-0.066758</td>\n",
       "      <td>-0.082255</td>\n",
       "      <td>0.09197126852125864</td>\n",
       "      <td>-0.119649</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>687</th>\n",
       "      <td>-0.5283696055510823</td>\n",
       "      <td>1.755924</td>\n",
       "      <td>-0.066758</td>\n",
       "      <td>-0.287892</td>\n",
       "      <td>0.09197126852125864</td>\n",
       "      <td>-0.195080</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>688</th>\n",
       "      <td>-1.1413554130948576</td>\n",
       "      <td>-0.914740</td>\n",
       "      <td>-0.652442</td>\n",
       "      <td>-0.493529</td>\n",
       "      <td>0.5522525384446895</td>\n",
       "      <td>-0.051321</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>689</th>\n",
       "      <td>0.28699350816676367</td>\n",
       "      <td>-0.277959</td>\n",
       "      <td>1.812810</td>\n",
       "      <td>-0.493529</td>\n",
       "      <td>-1.0587319062873184</td>\n",
       "      <td>-0.195272</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>666 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     var1      var2      var3      var4                  var5  \\\n",
       "0    -0.06173102354640747 -0.955920 -0.290872 -0.287892    0.1034783002693444   \n",
       "1       2.266444267315627 -0.060007  0.244013  0.740293   -0.8113307237034743   \n",
       "2     -0.5910898450678396 -0.855481 -0.216167 -0.493529    0.5522525384446895   \n",
       "3      -0.312611981613437 -0.646569  0.456175  0.534656  -0.48338031888302985   \n",
       "4     -0.9531946945445854  0.174015 -0.153415 -0.493529   -0.3683100014021721   \n",
       "..                    ...       ...       ...       ...                   ...   \n",
       "685   -0.8770941372642533  1.069928 -0.290872 -0.493529   0.43718222096383175   \n",
       "686   -0.7441272294887274 -0.805262 -0.066758 -0.082255   0.09197126852125864   \n",
       "687   -0.5283696055510823  1.755924 -0.066758 -0.287892   0.09197126852125864   \n",
       "688   -1.1413554130948576 -0.914740 -0.652442 -0.493529    0.5522525384446895   \n",
       "689   0.28699350816676367 -0.277959  1.812810 -0.493529   -1.0587319062873184   \n",
       "\n",
       "         var6 class  \n",
       "0   -0.195272     +  \n",
       "1   -0.087788     +  \n",
       "2   -0.037117     +  \n",
       "3   -0.194696     +  \n",
       "4   -0.195272     +  \n",
       "..        ...   ...  \n",
       "685 -0.195272     -  \n",
       "686 -0.119649     -  \n",
       "687 -0.195080     -  \n",
       "688 -0.051321     -  \n",
       "689 -0.195272     -  \n",
       "\n",
       "[666 rows x 7 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Put your code here\n",
    "! curl https://raw.githubusercontent.com/yangy5/HWFiles/main/cc_data.csv -O\n",
    "cc_data = pd.read_csv('cc_data.csv')\n",
    "cc_data.replace('?', pd.NA, inplace = True)\n",
    "\n",
    "cc = cc_data.dropna()\n",
    "cc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Relabeling the classes\n",
    "\n",
    "To simplify the process of modeling the credit card approval data, we should convert the class labels from strings to integers. For example, rather than `+`, we can consider this to be class \"`1`\".\n",
    "\n",
    "**&#9989; Task 2.2 (2 points):** Replace all of the strings in your \"Class\" column with integers based on the following:\n",
    "\n",
    "| original label | replaced label |\n",
    "| -------- | -------- |\n",
    "| + | 1 |\n",
    "| - | 0 |\n",
    "\n",
    "Once you've replaced the labels, display your DataFrame and confirm that it looks correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>var1</th>\n",
       "      <th>var2</th>\n",
       "      <th>var3</th>\n",
       "      <th>var4</th>\n",
       "      <th>var5</th>\n",
       "      <th>var6</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.06173102354640747</td>\n",
       "      <td>-0.955920</td>\n",
       "      <td>-0.290872</td>\n",
       "      <td>-0.287892</td>\n",
       "      <td>0.1034783002693444</td>\n",
       "      <td>-0.195272</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.266444267315627</td>\n",
       "      <td>-0.060007</td>\n",
       "      <td>0.244013</td>\n",
       "      <td>0.740293</td>\n",
       "      <td>-0.8113307237034743</td>\n",
       "      <td>-0.087788</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.5910898450678396</td>\n",
       "      <td>-0.855481</td>\n",
       "      <td>-0.216167</td>\n",
       "      <td>-0.493529</td>\n",
       "      <td>0.5522525384446895</td>\n",
       "      <td>-0.037117</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.312611981613437</td>\n",
       "      <td>-0.646569</td>\n",
       "      <td>0.456175</td>\n",
       "      <td>0.534656</td>\n",
       "      <td>-0.48338031888302985</td>\n",
       "      <td>-0.194696</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.9531946945445854</td>\n",
       "      <td>0.174015</td>\n",
       "      <td>-0.153415</td>\n",
       "      <td>-0.493529</td>\n",
       "      <td>-0.3683100014021721</td>\n",
       "      <td>-0.195272</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>685</th>\n",
       "      <td>-0.8770941372642533</td>\n",
       "      <td>1.069928</td>\n",
       "      <td>-0.290872</td>\n",
       "      <td>-0.493529</td>\n",
       "      <td>0.43718222096383175</td>\n",
       "      <td>-0.195272</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>686</th>\n",
       "      <td>-0.7441272294887274</td>\n",
       "      <td>-0.805262</td>\n",
       "      <td>-0.066758</td>\n",
       "      <td>-0.082255</td>\n",
       "      <td>0.09197126852125864</td>\n",
       "      <td>-0.119649</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>687</th>\n",
       "      <td>-0.5283696055510823</td>\n",
       "      <td>1.755924</td>\n",
       "      <td>-0.066758</td>\n",
       "      <td>-0.287892</td>\n",
       "      <td>0.09197126852125864</td>\n",
       "      <td>-0.195080</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>688</th>\n",
       "      <td>-1.1413554130948576</td>\n",
       "      <td>-0.914740</td>\n",
       "      <td>-0.652442</td>\n",
       "      <td>-0.493529</td>\n",
       "      <td>0.5522525384446895</td>\n",
       "      <td>-0.051321</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>689</th>\n",
       "      <td>0.28699350816676367</td>\n",
       "      <td>-0.277959</td>\n",
       "      <td>1.812810</td>\n",
       "      <td>-0.493529</td>\n",
       "      <td>-1.0587319062873184</td>\n",
       "      <td>-0.195272</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>666 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     var1      var2      var3      var4                  var5  \\\n",
       "0    -0.06173102354640747 -0.955920 -0.290872 -0.287892    0.1034783002693444   \n",
       "1       2.266444267315627 -0.060007  0.244013  0.740293   -0.8113307237034743   \n",
       "2     -0.5910898450678396 -0.855481 -0.216167 -0.493529    0.5522525384446895   \n",
       "3      -0.312611981613437 -0.646569  0.456175  0.534656  -0.48338031888302985   \n",
       "4     -0.9531946945445854  0.174015 -0.153415 -0.493529   -0.3683100014021721   \n",
       "..                    ...       ...       ...       ...                   ...   \n",
       "685   -0.8770941372642533  1.069928 -0.290872 -0.493529   0.43718222096383175   \n",
       "686   -0.7441272294887274 -0.805262 -0.066758 -0.082255   0.09197126852125864   \n",
       "687   -0.5283696055510823  1.755924 -0.066758 -0.287892   0.09197126852125864   \n",
       "688   -1.1413554130948576 -0.914740 -0.652442 -0.493529    0.5522525384446895   \n",
       "689   0.28699350816676367 -0.277959  1.812810 -0.493529   -1.0587319062873184   \n",
       "\n",
       "         var6  class  \n",
       "0   -0.195272      1  \n",
       "1   -0.087788      1  \n",
       "2   -0.037117      1  \n",
       "3   -0.194696      1  \n",
       "4   -0.195272      1  \n",
       "..        ...    ...  \n",
       "685 -0.195272      0  \n",
       "686 -0.119649      0  \n",
       "687 -0.195080      0  \n",
       "688 -0.051321      0  \n",
       "689 -0.195272      0  \n",
       "\n",
       "[666 rows x 7 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Put your code here\n",
    "ones = cc.replace('+', 1)\n",
    "cc_clean = ones.replace('-', 0)\n",
    "cc_clean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Separating the \"features\" from the \"labels\"\n",
    "\n",
    "As we've seen when working with `sklearn` it can be much easier to work with the data if we have separate variables that store the features and the labels.\n",
    "\n",
    "**&#9989; Task 2.3 (1 point):** Split your DataFrame so that you have two separate DataFrames, one called `features`, which contains all of the credit card approval features, and one called `labels`, which contains all of the *new* approval integer labels you just created. **Display both of these new DataFrames to make sure they look correct.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>var1</th>\n",
       "      <th>var2</th>\n",
       "      <th>var3</th>\n",
       "      <th>var4</th>\n",
       "      <th>var5</th>\n",
       "      <th>var6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.06173102354640747</td>\n",
       "      <td>-0.955920</td>\n",
       "      <td>-0.290872</td>\n",
       "      <td>-0.287892</td>\n",
       "      <td>0.1034783002693444</td>\n",
       "      <td>-0.195272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.266444267315627</td>\n",
       "      <td>-0.060007</td>\n",
       "      <td>0.244013</td>\n",
       "      <td>0.740293</td>\n",
       "      <td>-0.8113307237034743</td>\n",
       "      <td>-0.087788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.5910898450678396</td>\n",
       "      <td>-0.855481</td>\n",
       "      <td>-0.216167</td>\n",
       "      <td>-0.493529</td>\n",
       "      <td>0.5522525384446895</td>\n",
       "      <td>-0.037117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.312611981613437</td>\n",
       "      <td>-0.646569</td>\n",
       "      <td>0.456175</td>\n",
       "      <td>0.534656</td>\n",
       "      <td>-0.48338031888302985</td>\n",
       "      <td>-0.194696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.9531946945445854</td>\n",
       "      <td>0.174015</td>\n",
       "      <td>-0.153415</td>\n",
       "      <td>-0.493529</td>\n",
       "      <td>-0.3683100014021721</td>\n",
       "      <td>-0.195272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>685</th>\n",
       "      <td>-0.8770941372642533</td>\n",
       "      <td>1.069928</td>\n",
       "      <td>-0.290872</td>\n",
       "      <td>-0.493529</td>\n",
       "      <td>0.43718222096383175</td>\n",
       "      <td>-0.195272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>686</th>\n",
       "      <td>-0.7441272294887274</td>\n",
       "      <td>-0.805262</td>\n",
       "      <td>-0.066758</td>\n",
       "      <td>-0.082255</td>\n",
       "      <td>0.09197126852125864</td>\n",
       "      <td>-0.119649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>687</th>\n",
       "      <td>-0.5283696055510823</td>\n",
       "      <td>1.755924</td>\n",
       "      <td>-0.066758</td>\n",
       "      <td>-0.287892</td>\n",
       "      <td>0.09197126852125864</td>\n",
       "      <td>-0.195080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>688</th>\n",
       "      <td>-1.1413554130948576</td>\n",
       "      <td>-0.914740</td>\n",
       "      <td>-0.652442</td>\n",
       "      <td>-0.493529</td>\n",
       "      <td>0.5522525384446895</td>\n",
       "      <td>-0.051321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>689</th>\n",
       "      <td>0.28699350816676367</td>\n",
       "      <td>-0.277959</td>\n",
       "      <td>1.812810</td>\n",
       "      <td>-0.493529</td>\n",
       "      <td>-1.0587319062873184</td>\n",
       "      <td>-0.195272</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>666 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     var1      var2      var3      var4                  var5  \\\n",
       "0    -0.06173102354640747 -0.955920 -0.290872 -0.287892    0.1034783002693444   \n",
       "1       2.266444267315627 -0.060007  0.244013  0.740293   -0.8113307237034743   \n",
       "2     -0.5910898450678396 -0.855481 -0.216167 -0.493529    0.5522525384446895   \n",
       "3      -0.312611981613437 -0.646569  0.456175  0.534656  -0.48338031888302985   \n",
       "4     -0.9531946945445854  0.174015 -0.153415 -0.493529   -0.3683100014021721   \n",
       "..                    ...       ...       ...       ...                   ...   \n",
       "685   -0.8770941372642533  1.069928 -0.290872 -0.493529   0.43718222096383175   \n",
       "686   -0.7441272294887274 -0.805262 -0.066758 -0.082255   0.09197126852125864   \n",
       "687   -0.5283696055510823  1.755924 -0.066758 -0.287892   0.09197126852125864   \n",
       "688   -1.1413554130948576 -0.914740 -0.652442 -0.493529    0.5522525384446895   \n",
       "689   0.28699350816676367 -0.277959  1.812810 -0.493529   -1.0587319062873184   \n",
       "\n",
       "         var6  \n",
       "0   -0.195272  \n",
       "1   -0.087788  \n",
       "2   -0.037117  \n",
       "3   -0.194696  \n",
       "4   -0.195272  \n",
       "..        ...  \n",
       "685 -0.195272  \n",
       "686 -0.119649  \n",
       "687 -0.195080  \n",
       "688 -0.051321  \n",
       "689 -0.195272  \n",
       "\n",
       "[666 rows x 6 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Put your code here\n",
    "features = cc_clean[['var1', 'var2', 'var3', 'var4', 'var5', 'var6']]\n",
    "labels = cc_clean[['class']]\n",
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>685</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>686</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>687</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>688</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>689</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>666 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     class\n",
       "0        1\n",
       "1        1\n",
       "2        1\n",
       "3        1\n",
       "4        1\n",
       "..     ...\n",
       "685      0\n",
       "686      0\n",
       "687      0\n",
       "688      0\n",
       "689      0\n",
       "\n",
       "[666 rows x 1 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&#9989; **Question 2.1 (1 point):** How balanced are the classes? Does it matter for the set of classes to be balanced? Why or why not? (Include the code you used to determine this along with your written answer below.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=+3>&#9998;</font> They are not equal; there 68 more zeros than ones. However, this should not be much of a problem in this case because both of the classes have plenty of rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class\n",
      "0        367\n",
      "1        299\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "counts = labels.value_counts()\n",
    "print(counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### &#128721; STOP\n",
    "**Pause to commit your changes to your Git repository!**\n",
    "\n",
    "Take a moment to save your notebook, commit the changes to your Git repository `hw04_branch` using the commit message \"Committing Part 2\", and push the changes to GitHub.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 3. Building an SVC model (5 points)\n",
    "\n",
    "Now, to tackle this classification problem, we will use a support vector machine. Of course, we could easily replace this with any `sklearn` classifier we choose, but for now we will just use an SVC with a linear kernel.\n",
    "\n",
    "### 3.1 Splitting the data\n",
    "\n",
    "But first, we need to split our data into training and testing data!\n",
    "\n",
    "**&#9989; Task 3.1 (2 point):** Split your data into a training and testing set with a training set representing 80% of your data. For reproducibility , set the `random_state` argument to `1`. Print the lengths to show you have the right number of entries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put your code here\n",
    "X = features\n",
    "y = labels\n",
    "y = y.values.ravel() #converting the column to an array\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Modeling the data and evaluating the fit\n",
    "\n",
    "As you have done this a number of times at this point, we ask you to do most of the analysis for this problem in one cell.\n",
    "\n",
    "**&#9989; Task 3.2 (2 points):** Build a **sigmoid** kernel SVC model with `C=10.0`, fit it to the training set, and use the test features to predict the outcomes. Evaluate the fit using the **confusion matrix** and **classification report**.\n",
    "\n",
    "**First Note:** Double-check the documentation on the confusion matrix because the way `sklearn` outputs false positives and false negatives may be different from what most images on the web indicate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC(C=10.0, kernel=&#x27;sigmoid&#x27;, random_state=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(C=10.0, kernel=&#x27;sigmoid&#x27;, random_state=1)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "SVC(C=10.0, kernel='sigmoid', random_state=1)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Put your code here\n",
    "model = SVC(kernel = 'sigmoid', C = 10.0, random_state = 1)\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[51, 25],\n",
       "       [16, 42]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#confusion matrix\n",
    "y_pred = model.predict(X_test)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "print(\"Confusion Matrix:\")\n",
    "conf_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.67      0.71        76\n",
      "           1       0.63      0.72      0.67        58\n",
      "\n",
      "    accuracy                           0.69       134\n",
      "   macro avg       0.69      0.70      0.69       134\n",
      "weighted avg       0.70      0.69      0.70       134\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#class report\n",
    "report = classification_report(y_test, y_pred)\n",
    "print(\"Classification Report:\")\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&#9989; **Question 3.1 (1 point):** How accurate is your model? What evidence are you using to determine that? How many false positives and false negatives does it predict for each class?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=+3>&#9998;</font> The model is not very accurate thus far, considering that the weighted precision average is 70%. It predicted 25 false positives and 16 false negatives."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### &#128721; STOP\n",
    "**Pause to commit your changes to your Git repository!**\n",
    "\n",
    "Take a moment to save your notebook, commit the changes to your Git repository `hw04_branch` using the commit message \"Committing Part 3\", and push the changes to GitHub.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 4. Finding and using the best hyperparameters (8 points)\n",
    "\n",
    "At this point, we have fit one model and determined it's performance, but is it the best model? We can use `GridSearchCV` to find the best model (given our choices of parameters). Once we do that, we will use that \"best\" model for making predictions. \n",
    "\n",
    "\n",
    "### 4.1 Performing a grid search\n",
    "\n",
    "**&#9989; Task 4.1 (4 points):** Using the following parameters `C` = `0.1`, `1.0`, `10.0`, `100.0`, `1000.0` and `gamma` = `0.01`, `0.1`, `1.0`, `10.0` for a `linear`, `rbf`, and `sigmoid` kernels use `GridSearchCV` with the `SVC()` model to find the best fit parameters. Once, you're run the grid search, print the \"best params\" that the grid search found (*hint*: there's an attribute associated with the GridSearchCV object that stores this information). Note that this code could take a while to run since it is repeatedly training your SVM. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 60 candidates, totalling 300 fits\n",
      "[CV 1/5] END ..C=0.1, gamma=0.01, kernel=linear;, score=0.776 total time=   0.0s\n",
      "[CV 2/5] END ..C=0.1, gamma=0.01, kernel=linear;, score=0.748 total time=   0.0s\n",
      "[CV 3/5] END ..C=0.1, gamma=0.01, kernel=linear;, score=0.764 total time=   0.0s\n",
      "[CV 4/5] END ..C=0.1, gamma=0.01, kernel=linear;, score=0.764 total time=   0.0s\n",
      "[CV 5/5] END ..C=0.1, gamma=0.01, kernel=linear;, score=0.708 total time=   0.0s\n",
      "[CV 1/5] END .....C=0.1, gamma=0.01, kernel=rbf;, score=0.617 total time=   0.0s\n",
      "[CV 2/5] END .....C=0.1, gamma=0.01, kernel=rbf;, score=0.626 total time=   0.0s\n",
      "[CV 3/5] END .....C=0.1, gamma=0.01, kernel=rbf;, score=0.604 total time=   0.0s\n",
      "[CV 4/5] END .....C=0.1, gamma=0.01, kernel=rbf;, score=0.651 total time=   0.0s\n",
      "[CV 5/5] END .....C=0.1, gamma=0.01, kernel=rbf;, score=0.642 total time=   0.0s\n",
      "[CV 1/5] END .C=0.1, gamma=0.01, kernel=sigmoid;, score=0.570 total time=   0.0s\n",
      "[CV 2/5] END .C=0.1, gamma=0.01, kernel=sigmoid;, score=0.561 total time=   0.0s\n",
      "[CV 3/5] END .C=0.1, gamma=0.01, kernel=sigmoid;, score=0.566 total time=   0.0s\n",
      "[CV 4/5] END .C=0.1, gamma=0.01, kernel=sigmoid;, score=0.585 total time=   0.0s\n",
      "[CV 5/5] END .C=0.1, gamma=0.01, kernel=sigmoid;, score=0.547 total time=   0.0s\n",
      "[CV 1/5] END ...C=0.1, gamma=0.1, kernel=linear;, score=0.776 total time=   0.0s\n",
      "[CV 2/5] END ...C=0.1, gamma=0.1, kernel=linear;, score=0.748 total time=   0.0s\n",
      "[CV 3/5] END ...C=0.1, gamma=0.1, kernel=linear;, score=0.764 total time=   0.0s\n",
      "[CV 4/5] END ...C=0.1, gamma=0.1, kernel=linear;, score=0.764 total time=   0.0s\n",
      "[CV 5/5] END ...C=0.1, gamma=0.1, kernel=linear;, score=0.708 total time=   0.0s\n",
      "[CV 1/5] END ......C=0.1, gamma=0.1, kernel=rbf;, score=0.766 total time=   0.0s\n",
      "[CV 2/5] END ......C=0.1, gamma=0.1, kernel=rbf;, score=0.748 total time=   0.0s\n",
      "[CV 3/5] END ......C=0.1, gamma=0.1, kernel=rbf;, score=0.755 total time=   0.0s\n",
      "[CV 4/5] END ......C=0.1, gamma=0.1, kernel=rbf;, score=0.736 total time=   0.0s\n",
      "[CV 5/5] END ......C=0.1, gamma=0.1, kernel=rbf;, score=0.689 total time=   0.0s\n",
      "[CV 1/5] END ..C=0.1, gamma=0.1, kernel=sigmoid;, score=0.757 total time=   0.0s\n",
      "[CV 2/5] END ..C=0.1, gamma=0.1, kernel=sigmoid;, score=0.729 total time=   0.0s\n",
      "[CV 3/5] END ..C=0.1, gamma=0.1, kernel=sigmoid;, score=0.726 total time=   0.0s\n",
      "[CV 4/5] END ..C=0.1, gamma=0.1, kernel=sigmoid;, score=0.726 total time=   0.0s\n",
      "[CV 5/5] END ..C=0.1, gamma=0.1, kernel=sigmoid;, score=0.698 total time=   0.0s\n",
      "[CV 1/5] END ...C=0.1, gamma=1.0, kernel=linear;, score=0.776 total time=   0.0s\n",
      "[CV 2/5] END ...C=0.1, gamma=1.0, kernel=linear;, score=0.748 total time=   0.0s\n",
      "[CV 3/5] END ...C=0.1, gamma=1.0, kernel=linear;, score=0.764 total time=   0.0s\n",
      "[CV 4/5] END ...C=0.1, gamma=1.0, kernel=linear;, score=0.764 total time=   0.0s\n",
      "[CV 5/5] END ...C=0.1, gamma=1.0, kernel=linear;, score=0.708 total time=   0.0s\n",
      "[CV 1/5] END ......C=0.1, gamma=1.0, kernel=rbf;, score=0.776 total time=   0.0s\n",
      "[CV 2/5] END ......C=0.1, gamma=1.0, kernel=rbf;, score=0.692 total time=   0.0s\n",
      "[CV 3/5] END ......C=0.1, gamma=1.0, kernel=rbf;, score=0.755 total time=   0.0s\n",
      "[CV 4/5] END ......C=0.1, gamma=1.0, kernel=rbf;, score=0.689 total time=   0.0s\n",
      "[CV 5/5] END ......C=0.1, gamma=1.0, kernel=rbf;, score=0.660 total time=   0.0s\n",
      "[CV 1/5] END ..C=0.1, gamma=1.0, kernel=sigmoid;, score=0.682 total time=   0.0s\n",
      "[CV 2/5] END ..C=0.1, gamma=1.0, kernel=sigmoid;, score=0.682 total time=   0.0s\n",
      "[CV 3/5] END ..C=0.1, gamma=1.0, kernel=sigmoid;, score=0.632 total time=   0.0s\n",
      "[CV 4/5] END ..C=0.1, gamma=1.0, kernel=sigmoid;, score=0.585 total time=   0.0s\n",
      "[CV 5/5] END ..C=0.1, gamma=1.0, kernel=sigmoid;, score=0.679 total time=   0.0s\n",
      "[CV 1/5] END ..C=0.1, gamma=10.0, kernel=linear;, score=0.776 total time=   0.0s\n",
      "[CV 2/5] END ..C=0.1, gamma=10.0, kernel=linear;, score=0.748 total time=   0.0s\n",
      "[CV 3/5] END ..C=0.1, gamma=10.0, kernel=linear;, score=0.764 total time=   0.0s\n",
      "[CV 4/5] END ..C=0.1, gamma=10.0, kernel=linear;, score=0.764 total time=   0.0s\n",
      "[CV 5/5] END ..C=0.1, gamma=10.0, kernel=linear;, score=0.708 total time=   0.0s\n",
      "[CV 1/5] END .....C=0.1, gamma=10.0, kernel=rbf;, score=0.542 total time=   0.0s\n",
      "[CV 2/5] END .....C=0.1, gamma=10.0, kernel=rbf;, score=0.551 total time=   0.0s\n",
      "[CV 3/5] END .....C=0.1, gamma=10.0, kernel=rbf;, score=0.547 total time=   0.0s\n",
      "[CV 4/5] END .....C=0.1, gamma=10.0, kernel=rbf;, score=0.547 total time=   0.0s\n",
      "[CV 5/5] END .....C=0.1, gamma=10.0, kernel=rbf;, score=0.547 total time=   0.0s\n",
      "[CV 1/5] END .C=0.1, gamma=10.0, kernel=sigmoid;, score=0.533 total time=   0.0s\n",
      "[CV 2/5] END .C=0.1, gamma=10.0, kernel=sigmoid;, score=0.626 total time=   0.0s\n",
      "[CV 3/5] END .C=0.1, gamma=10.0, kernel=sigmoid;, score=0.557 total time=   0.0s\n",
      "[CV 4/5] END .C=0.1, gamma=10.0, kernel=sigmoid;, score=0.519 total time=   0.0s\n",
      "[CV 5/5] END .C=0.1, gamma=10.0, kernel=sigmoid;, score=0.623 total time=   0.0s\n",
      "[CV 1/5] END ..C=1.0, gamma=0.01, kernel=linear;, score=0.766 total time=   0.0s\n",
      "[CV 2/5] END ..C=1.0, gamma=0.01, kernel=linear;, score=0.748 total time=   0.0s\n",
      "[CV 3/5] END ..C=1.0, gamma=0.01, kernel=linear;, score=0.783 total time=   0.0s\n",
      "[CV 4/5] END ..C=1.0, gamma=0.01, kernel=linear;, score=0.745 total time=   0.0s\n",
      "[CV 5/5] END ..C=1.0, gamma=0.01, kernel=linear;, score=0.726 total time=   0.0s\n",
      "[CV 1/5] END .....C=1.0, gamma=0.01, kernel=rbf;, score=0.766 total time=   0.0s\n",
      "[CV 2/5] END .....C=1.0, gamma=0.01, kernel=rbf;, score=0.738 total time=   0.0s\n",
      "[CV 3/5] END .....C=1.0, gamma=0.01, kernel=rbf;, score=0.745 total time=   0.0s\n",
      "[CV 4/5] END .....C=1.0, gamma=0.01, kernel=rbf;, score=0.745 total time=   0.0s\n",
      "[CV 5/5] END .....C=1.0, gamma=0.01, kernel=rbf;, score=0.717 total time=   0.0s\n",
      "[CV 1/5] END .C=1.0, gamma=0.01, kernel=sigmoid;, score=0.757 total time=   0.0s\n",
      "[CV 2/5] END .C=1.0, gamma=0.01, kernel=sigmoid;, score=0.729 total time=   0.0s\n",
      "[CV 3/5] END .C=1.0, gamma=0.01, kernel=sigmoid;, score=0.717 total time=   0.0s\n",
      "[CV 4/5] END .C=1.0, gamma=0.01, kernel=sigmoid;, score=0.726 total time=   0.0s\n",
      "[CV 5/5] END .C=1.0, gamma=0.01, kernel=sigmoid;, score=0.689 total time=   0.0s\n",
      "[CV 1/5] END ...C=1.0, gamma=0.1, kernel=linear;, score=0.766 total time=   0.0s\n",
      "[CV 2/5] END ...C=1.0, gamma=0.1, kernel=linear;, score=0.748 total time=   0.0s\n",
      "[CV 3/5] END ...C=1.0, gamma=0.1, kernel=linear;, score=0.783 total time=   0.0s\n",
      "[CV 4/5] END ...C=1.0, gamma=0.1, kernel=linear;, score=0.745 total time=   0.0s\n",
      "[CV 5/5] END ...C=1.0, gamma=0.1, kernel=linear;, score=0.726 total time=   0.0s\n",
      "[CV 1/5] END ......C=1.0, gamma=0.1, kernel=rbf;, score=0.766 total time=   0.0s\n",
      "[CV 2/5] END ......C=1.0, gamma=0.1, kernel=rbf;, score=0.729 total time=   0.0s\n",
      "[CV 3/5] END ......C=1.0, gamma=0.1, kernel=rbf;, score=0.802 total time=   0.0s\n",
      "[CV 4/5] END ......C=1.0, gamma=0.1, kernel=rbf;, score=0.764 total time=   0.0s\n",
      "[CV 5/5] END ......C=1.0, gamma=0.1, kernel=rbf;, score=0.717 total time=   0.0s\n",
      "[CV 1/5] END ..C=1.0, gamma=0.1, kernel=sigmoid;, score=0.785 total time=   0.0s\n",
      "[CV 2/5] END ..C=1.0, gamma=0.1, kernel=sigmoid;, score=0.710 total time=   0.0s\n",
      "[CV 3/5] END ..C=1.0, gamma=0.1, kernel=sigmoid;, score=0.811 total time=   0.0s\n",
      "[CV 4/5] END ..C=1.0, gamma=0.1, kernel=sigmoid;, score=0.698 total time=   0.0s\n",
      "[CV 5/5] END ..C=1.0, gamma=0.1, kernel=sigmoid;, score=0.717 total time=   0.0s\n",
      "[CV 1/5] END ...C=1.0, gamma=1.0, kernel=linear;, score=0.766 total time=   0.0s\n",
      "[CV 2/5] END ...C=1.0, gamma=1.0, kernel=linear;, score=0.748 total time=   0.0s\n",
      "[CV 3/5] END ...C=1.0, gamma=1.0, kernel=linear;, score=0.783 total time=   0.0s\n",
      "[CV 4/5] END ...C=1.0, gamma=1.0, kernel=linear;, score=0.745 total time=   0.0s\n",
      "[CV 5/5] END ...C=1.0, gamma=1.0, kernel=linear;, score=0.726 total time=   0.0s\n",
      "[CV 1/5] END ......C=1.0, gamma=1.0, kernel=rbf;, score=0.813 total time=   0.0s\n",
      "[CV 2/5] END ......C=1.0, gamma=1.0, kernel=rbf;, score=0.748 total time=   0.0s\n",
      "[CV 3/5] END ......C=1.0, gamma=1.0, kernel=rbf;, score=0.755 total time=   0.0s\n",
      "[CV 4/5] END ......C=1.0, gamma=1.0, kernel=rbf;, score=0.755 total time=   0.0s\n",
      "[CV 5/5] END ......C=1.0, gamma=1.0, kernel=rbf;, score=0.726 total time=   0.0s\n",
      "[CV 1/5] END ..C=1.0, gamma=1.0, kernel=sigmoid;, score=0.626 total time=   0.0s\n",
      "[CV 2/5] END ..C=1.0, gamma=1.0, kernel=sigmoid;, score=0.617 total time=   0.0s\n",
      "[CV 3/5] END ..C=1.0, gamma=1.0, kernel=sigmoid;, score=0.575 total time=   0.0s\n",
      "[CV 4/5] END ..C=1.0, gamma=1.0, kernel=sigmoid;, score=0.528 total time=   0.0s\n",
      "[CV 5/5] END ..C=1.0, gamma=1.0, kernel=sigmoid;, score=0.557 total time=   0.0s\n",
      "[CV 1/5] END ..C=1.0, gamma=10.0, kernel=linear;, score=0.766 total time=   0.0s\n",
      "[CV 2/5] END ..C=1.0, gamma=10.0, kernel=linear;, score=0.748 total time=   0.0s\n",
      "[CV 3/5] END ..C=1.0, gamma=10.0, kernel=linear;, score=0.783 total time=   0.0s\n",
      "[CV 4/5] END ..C=1.0, gamma=10.0, kernel=linear;, score=0.745 total time=   0.0s\n",
      "[CV 5/5] END ..C=1.0, gamma=10.0, kernel=linear;, score=0.726 total time=   0.0s\n",
      "[CV 1/5] END .....C=1.0, gamma=10.0, kernel=rbf;, score=0.748 total time=   0.0s\n",
      "[CV 2/5] END .....C=1.0, gamma=10.0, kernel=rbf;, score=0.729 total time=   0.0s\n",
      "[CV 3/5] END .....C=1.0, gamma=10.0, kernel=rbf;, score=0.736 total time=   0.0s\n",
      "[CV 4/5] END .....C=1.0, gamma=10.0, kernel=rbf;, score=0.642 total time=   0.0s\n",
      "[CV 5/5] END .....C=1.0, gamma=10.0, kernel=rbf;, score=0.745 total time=   0.0s\n",
      "[CV 1/5] END .C=1.0, gamma=10.0, kernel=sigmoid;, score=0.533 total time=   0.0s\n",
      "[CV 2/5] END .C=1.0, gamma=10.0, kernel=sigmoid;, score=0.598 total time=   0.0s\n",
      "[CV 3/5] END .C=1.0, gamma=10.0, kernel=sigmoid;, score=0.547 total time=   0.0s\n",
      "[CV 4/5] END .C=1.0, gamma=10.0, kernel=sigmoid;, score=0.557 total time=   0.0s\n",
      "[CV 5/5] END .C=1.0, gamma=10.0, kernel=sigmoid;, score=0.604 total time=   0.0s\n",
      "[CV 1/5] END .C=10.0, gamma=0.01, kernel=linear;, score=0.766 total time=   0.0s\n",
      "[CV 2/5] END .C=10.0, gamma=0.01, kernel=linear;, score=0.757 total time=   0.0s\n",
      "[CV 3/5] END .C=10.0, gamma=0.01, kernel=linear;, score=0.792 total time=   0.0s\n",
      "[CV 4/5] END .C=10.0, gamma=0.01, kernel=linear;, score=0.745 total time=   0.0s\n",
      "[CV 5/5] END .C=10.0, gamma=0.01, kernel=linear;, score=0.745 total time=   0.0s\n",
      "[CV 1/5] END ....C=10.0, gamma=0.01, kernel=rbf;, score=0.776 total time=   0.0s\n",
      "[CV 2/5] END ....C=10.0, gamma=0.01, kernel=rbf;, score=0.757 total time=   0.0s\n",
      "[CV 3/5] END ....C=10.0, gamma=0.01, kernel=rbf;, score=0.774 total time=   0.0s\n",
      "[CV 4/5] END ....C=10.0, gamma=0.01, kernel=rbf;, score=0.755 total time=   0.0s\n",
      "[CV 5/5] END ....C=10.0, gamma=0.01, kernel=rbf;, score=0.726 total time=   0.0s\n",
      "[CV 1/5] END C=10.0, gamma=0.01, kernel=sigmoid;, score=0.776 total time=   0.0s\n",
      "[CV 2/5] END C=10.0, gamma=0.01, kernel=sigmoid;, score=0.748 total time=   0.0s\n",
      "[CV 3/5] END C=10.0, gamma=0.01, kernel=sigmoid;, score=0.764 total time=   0.0s\n",
      "[CV 4/5] END C=10.0, gamma=0.01, kernel=sigmoid;, score=0.764 total time=   0.0s\n",
      "[CV 5/5] END C=10.0, gamma=0.01, kernel=sigmoid;, score=0.717 total time=   0.0s\n",
      "[CV 1/5] END ..C=10.0, gamma=0.1, kernel=linear;, score=0.766 total time=   0.0s\n",
      "[CV 2/5] END ..C=10.0, gamma=0.1, kernel=linear;, score=0.757 total time=   0.0s\n",
      "[CV 3/5] END ..C=10.0, gamma=0.1, kernel=linear;, score=0.792 total time=   0.0s\n",
      "[CV 4/5] END ..C=10.0, gamma=0.1, kernel=linear;, score=0.745 total time=   0.0s\n",
      "[CV 5/5] END ..C=10.0, gamma=0.1, kernel=linear;, score=0.745 total time=   0.0s\n",
      "[CV 1/5] END .....C=10.0, gamma=0.1, kernel=rbf;, score=0.804 total time=   0.0s\n",
      "[CV 2/5] END .....C=10.0, gamma=0.1, kernel=rbf;, score=0.738 total time=   0.0s\n",
      "[CV 3/5] END .....C=10.0, gamma=0.1, kernel=rbf;, score=0.811 total time=   0.0s\n",
      "[CV 4/5] END .....C=10.0, gamma=0.1, kernel=rbf;, score=0.755 total time=   0.0s\n",
      "[CV 5/5] END .....C=10.0, gamma=0.1, kernel=rbf;, score=0.726 total time=   0.0s\n",
      "[CV 1/5] END .C=10.0, gamma=0.1, kernel=sigmoid;, score=0.748 total time=   0.0s\n",
      "[CV 2/5] END .C=10.0, gamma=0.1, kernel=sigmoid;, score=0.720 total time=   0.0s\n",
      "[CV 3/5] END .C=10.0, gamma=0.1, kernel=sigmoid;, score=0.736 total time=   0.0s\n",
      "[CV 4/5] END .C=10.0, gamma=0.1, kernel=sigmoid;, score=0.613 total time=   0.0s\n",
      "[CV 5/5] END .C=10.0, gamma=0.1, kernel=sigmoid;, score=0.783 total time=   0.0s\n",
      "[CV 1/5] END ..C=10.0, gamma=1.0, kernel=linear;, score=0.766 total time=   0.0s\n",
      "[CV 2/5] END ..C=10.0, gamma=1.0, kernel=linear;, score=0.757 total time=   0.0s\n",
      "[CV 3/5] END ..C=10.0, gamma=1.0, kernel=linear;, score=0.792 total time=   0.0s\n",
      "[CV 4/5] END ..C=10.0, gamma=1.0, kernel=linear;, score=0.745 total time=   0.0s\n",
      "[CV 5/5] END ..C=10.0, gamma=1.0, kernel=linear;, score=0.745 total time=   0.0s\n",
      "[CV 1/5] END .....C=10.0, gamma=1.0, kernel=rbf;, score=0.794 total time=   0.0s\n",
      "[CV 2/5] END .....C=10.0, gamma=1.0, kernel=rbf;, score=0.757 total time=   0.0s\n",
      "[CV 3/5] END .....C=10.0, gamma=1.0, kernel=rbf;, score=0.736 total time=   0.0s\n",
      "[CV 4/5] END .....C=10.0, gamma=1.0, kernel=rbf;, score=0.708 total time=   0.0s\n",
      "[CV 5/5] END .....C=10.0, gamma=1.0, kernel=rbf;, score=0.792 total time=   0.0s\n",
      "[CV 1/5] END .C=10.0, gamma=1.0, kernel=sigmoid;, score=0.626 total time=   0.0s\n",
      "[CV 2/5] END .C=10.0, gamma=1.0, kernel=sigmoid;, score=0.607 total time=   0.0s\n",
      "[CV 3/5] END .C=10.0, gamma=1.0, kernel=sigmoid;, score=0.566 total time=   0.0s\n",
      "[CV 4/5] END .C=10.0, gamma=1.0, kernel=sigmoid;, score=0.528 total time=   0.0s\n",
      "[CV 5/5] END .C=10.0, gamma=1.0, kernel=sigmoid;, score=0.547 total time=   0.0s\n",
      "[CV 1/5] END .C=10.0, gamma=10.0, kernel=linear;, score=0.766 total time=   0.0s\n",
      "[CV 2/5] END .C=10.0, gamma=10.0, kernel=linear;, score=0.757 total time=   0.0s\n",
      "[CV 3/5] END .C=10.0, gamma=10.0, kernel=linear;, score=0.792 total time=   0.0s\n",
      "[CV 4/5] END .C=10.0, gamma=10.0, kernel=linear;, score=0.745 total time=   0.0s\n",
      "[CV 5/5] END .C=10.0, gamma=10.0, kernel=linear;, score=0.745 total time=   0.0s\n",
      "[CV 1/5] END ....C=10.0, gamma=10.0, kernel=rbf;, score=0.766 total time=   0.0s\n",
      "[CV 2/5] END ....C=10.0, gamma=10.0, kernel=rbf;, score=0.701 total time=   0.0s\n",
      "[CV 3/5] END ....C=10.0, gamma=10.0, kernel=rbf;, score=0.717 total time=   0.0s\n",
      "[CV 4/5] END ....C=10.0, gamma=10.0, kernel=rbf;, score=0.670 total time=   0.0s\n",
      "[CV 5/5] END ....C=10.0, gamma=10.0, kernel=rbf;, score=0.698 total time=   0.0s\n",
      "[CV 1/5] END C=10.0, gamma=10.0, kernel=sigmoid;, score=0.533 total time=   0.0s\n",
      "[CV 2/5] END C=10.0, gamma=10.0, kernel=sigmoid;, score=0.579 total time=   0.0s\n",
      "[CV 3/5] END C=10.0, gamma=10.0, kernel=sigmoid;, score=0.509 total time=   0.0s\n",
      "[CV 4/5] END C=10.0, gamma=10.0, kernel=sigmoid;, score=0.566 total time=   0.0s\n",
      "[CV 5/5] END C=10.0, gamma=10.0, kernel=sigmoid;, score=0.604 total time=   0.0s\n",
      "[CV 1/5] END C=100.0, gamma=0.01, kernel=linear;, score=0.766 total time=   0.1s\n",
      "[CV 2/5] END C=100.0, gamma=0.01, kernel=linear;, score=0.757 total time=   0.1s\n",
      "[CV 3/5] END C=100.0, gamma=0.01, kernel=linear;, score=0.783 total time=   0.1s\n",
      "[CV 4/5] END C=100.0, gamma=0.01, kernel=linear;, score=0.745 total time=   0.1s\n",
      "[CV 5/5] END C=100.0, gamma=0.01, kernel=linear;, score=0.745 total time=   0.1s\n",
      "[CV 1/5] END ...C=100.0, gamma=0.01, kernel=rbf;, score=0.785 total time=   0.0s\n",
      "[CV 2/5] END ...C=100.0, gamma=0.01, kernel=rbf;, score=0.757 total time=   0.0s\n",
      "[CV 3/5] END ...C=100.0, gamma=0.01, kernel=rbf;, score=0.792 total time=   0.0s\n",
      "[CV 4/5] END ...C=100.0, gamma=0.01, kernel=rbf;, score=0.745 total time=   0.0s\n",
      "[CV 5/5] END ...C=100.0, gamma=0.01, kernel=rbf;, score=0.755 total time=   0.0s\n",
      "[CV 1/5] END C=100.0, gamma=0.01, kernel=sigmoid;, score=0.748 total time=   0.0s\n",
      "[CV 2/5] END C=100.0, gamma=0.01, kernel=sigmoid;, score=0.766 total time=   0.0s\n",
      "[CV 3/5] END C=100.0, gamma=0.01, kernel=sigmoid;, score=0.755 total time=   0.0s\n",
      "[CV 4/5] END C=100.0, gamma=0.01, kernel=sigmoid;, score=0.717 total time=   0.0s\n",
      "[CV 5/5] END C=100.0, gamma=0.01, kernel=sigmoid;, score=0.717 total time=   0.0s\n",
      "[CV 1/5] END .C=100.0, gamma=0.1, kernel=linear;, score=0.766 total time=   0.1s\n",
      "[CV 2/5] END .C=100.0, gamma=0.1, kernel=linear;, score=0.757 total time=   0.1s\n",
      "[CV 3/5] END .C=100.0, gamma=0.1, kernel=linear;, score=0.783 total time=   0.1s\n",
      "[CV 4/5] END .C=100.0, gamma=0.1, kernel=linear;, score=0.745 total time=   0.1s\n",
      "[CV 5/5] END .C=100.0, gamma=0.1, kernel=linear;, score=0.745 total time=   0.1s\n",
      "[CV 1/5] END ....C=100.0, gamma=0.1, kernel=rbf;, score=0.813 total time=   0.0s\n",
      "[CV 2/5] END ....C=100.0, gamma=0.1, kernel=rbf;, score=0.748 total time=   0.0s\n",
      "[CV 3/5] END ....C=100.0, gamma=0.1, kernel=rbf;, score=0.821 total time=   0.0s\n",
      "[CV 4/5] END ....C=100.0, gamma=0.1, kernel=rbf;, score=0.792 total time=   0.0s\n",
      "[CV 5/5] END ....C=100.0, gamma=0.1, kernel=rbf;, score=0.745 total time=   0.0s\n",
      "[CV 1/5] END C=100.0, gamma=0.1, kernel=sigmoid;, score=0.738 total time=   0.0s\n",
      "[CV 2/5] END C=100.0, gamma=0.1, kernel=sigmoid;, score=0.701 total time=   0.0s\n",
      "[CV 3/5] END C=100.0, gamma=0.1, kernel=sigmoid;, score=0.745 total time=   0.0s\n",
      "[CV 4/5] END C=100.0, gamma=0.1, kernel=sigmoid;, score=0.604 total time=   0.0s\n",
      "[CV 5/5] END C=100.0, gamma=0.1, kernel=sigmoid;, score=0.774 total time=   0.0s\n",
      "[CV 1/5] END .C=100.0, gamma=1.0, kernel=linear;, score=0.766 total time=   0.1s\n",
      "[CV 2/5] END .C=100.0, gamma=1.0, kernel=linear;, score=0.757 total time=   0.1s\n",
      "[CV 3/5] END .C=100.0, gamma=1.0, kernel=linear;, score=0.783 total time=   0.1s\n",
      "[CV 4/5] END .C=100.0, gamma=1.0, kernel=linear;, score=0.745 total time=   0.1s\n",
      "[CV 5/5] END .C=100.0, gamma=1.0, kernel=linear;, score=0.745 total time=   0.1s\n",
      "[CV 1/5] END ....C=100.0, gamma=1.0, kernel=rbf;, score=0.766 total time=   0.0s\n",
      "[CV 2/5] END ....C=100.0, gamma=1.0, kernel=rbf;, score=0.757 total time=   0.0s\n",
      "[CV 3/5] END ....C=100.0, gamma=1.0, kernel=rbf;, score=0.698 total time=   0.0s\n",
      "[CV 4/5] END ....C=100.0, gamma=1.0, kernel=rbf;, score=0.623 total time=   0.0s\n",
      "[CV 5/5] END ....C=100.0, gamma=1.0, kernel=rbf;, score=0.736 total time=   0.0s\n",
      "[CV 1/5] END C=100.0, gamma=1.0, kernel=sigmoid;, score=0.626 total time=   0.0s\n",
      "[CV 2/5] END C=100.0, gamma=1.0, kernel=sigmoid;, score=0.607 total time=   0.0s\n",
      "[CV 3/5] END C=100.0, gamma=1.0, kernel=sigmoid;, score=0.575 total time=   0.0s\n",
      "[CV 4/5] END C=100.0, gamma=1.0, kernel=sigmoid;, score=0.528 total time=   0.0s\n",
      "[CV 5/5] END C=100.0, gamma=1.0, kernel=sigmoid;, score=0.566 total time=   0.0s\n",
      "[CV 1/5] END C=100.0, gamma=10.0, kernel=linear;, score=0.766 total time=   0.1s\n",
      "[CV 2/5] END C=100.0, gamma=10.0, kernel=linear;, score=0.757 total time=   0.1s\n",
      "[CV 3/5] END C=100.0, gamma=10.0, kernel=linear;, score=0.783 total time=   0.1s\n",
      "[CV 4/5] END C=100.0, gamma=10.0, kernel=linear;, score=0.745 total time=   0.1s\n",
      "[CV 5/5] END C=100.0, gamma=10.0, kernel=linear;, score=0.745 total time=   0.1s\n",
      "[CV 1/5] END ...C=100.0, gamma=10.0, kernel=rbf;, score=0.757 total time=   0.0s\n",
      "[CV 2/5] END ...C=100.0, gamma=10.0, kernel=rbf;, score=0.710 total time=   0.0s\n",
      "[CV 3/5] END ...C=100.0, gamma=10.0, kernel=rbf;, score=0.717 total time=   0.0s\n",
      "[CV 4/5] END ...C=100.0, gamma=10.0, kernel=rbf;, score=0.670 total time=   0.0s\n",
      "[CV 5/5] END ...C=100.0, gamma=10.0, kernel=rbf;, score=0.689 total time=   0.0s\n",
      "[CV 1/5] END C=100.0, gamma=10.0, kernel=sigmoid;, score=0.533 total time=   0.0s\n",
      "[CV 2/5] END C=100.0, gamma=10.0, kernel=sigmoid;, score=0.579 total time=   0.0s\n",
      "[CV 3/5] END C=100.0, gamma=10.0, kernel=sigmoid;, score=0.538 total time=   0.0s\n",
      "[CV 4/5] END C=100.0, gamma=10.0, kernel=sigmoid;, score=0.557 total time=   0.0s\n",
      "[CV 5/5] END C=100.0, gamma=10.0, kernel=sigmoid;, score=0.604 total time=   0.0s\n",
      "[CV 1/5] END C=1000.0, gamma=0.01, kernel=linear;, score=0.766 total time=   0.4s\n",
      "[CV 2/5] END C=1000.0, gamma=0.01, kernel=linear;, score=0.757 total time=   0.6s\n",
      "[CV 3/5] END C=1000.0, gamma=0.01, kernel=linear;, score=0.783 total time=   0.5s\n",
      "[CV 4/5] END C=1000.0, gamma=0.01, kernel=linear;, score=0.745 total time=   0.4s\n",
      "[CV 5/5] END C=1000.0, gamma=0.01, kernel=linear;, score=0.745 total time=   0.8s\n",
      "[CV 1/5] END ..C=1000.0, gamma=0.01, kernel=rbf;, score=0.776 total time=   0.0s\n",
      "[CV 2/5] END ..C=1000.0, gamma=0.01, kernel=rbf;, score=0.738 total time=   0.0s\n",
      "[CV 3/5] END ..C=1000.0, gamma=0.01, kernel=rbf;, score=0.811 total time=   0.0s\n",
      "[CV 4/5] END ..C=1000.0, gamma=0.01, kernel=rbf;, score=0.726 total time=   0.0s\n",
      "[CV 5/5] END ..C=1000.0, gamma=0.01, kernel=rbf;, score=0.736 total time=   0.0s\n",
      "[CV 1/5] END C=1000.0, gamma=0.01, kernel=sigmoid;, score=0.757 total time=   0.0s\n",
      "[CV 2/5] END C=1000.0, gamma=0.01, kernel=sigmoid;, score=0.766 total time=   0.0s\n",
      "[CV 3/5] END C=1000.0, gamma=0.01, kernel=sigmoid;, score=0.755 total time=   0.0s\n",
      "[CV 4/5] END C=1000.0, gamma=0.01, kernel=sigmoid;, score=0.698 total time=   0.0s\n",
      "[CV 5/5] END C=1000.0, gamma=0.01, kernel=sigmoid;, score=0.755 total time=   0.0s\n",
      "[CV 1/5] END C=1000.0, gamma=0.1, kernel=linear;, score=0.766 total time=   0.4s\n",
      "[CV 2/5] END C=1000.0, gamma=0.1, kernel=linear;, score=0.757 total time=   0.6s\n",
      "[CV 3/5] END C=1000.0, gamma=0.1, kernel=linear;, score=0.783 total time=   0.5s\n",
      "[CV 4/5] END C=1000.0, gamma=0.1, kernel=linear;, score=0.745 total time=   0.4s\n",
      "[CV 5/5] END C=1000.0, gamma=0.1, kernel=linear;, score=0.745 total time=   0.8s\n",
      "[CV 1/5] END ...C=1000.0, gamma=0.1, kernel=rbf;, score=0.776 total time=   0.1s\n",
      "[CV 2/5] END ...C=1000.0, gamma=0.1, kernel=rbf;, score=0.757 total time=   0.1s\n",
      "[CV 3/5] END ...C=1000.0, gamma=0.1, kernel=rbf;, score=0.774 total time=   0.0s\n",
      "[CV 4/5] END ...C=1000.0, gamma=0.1, kernel=rbf;, score=0.764 total time=   0.0s\n",
      "[CV 5/5] END ...C=1000.0, gamma=0.1, kernel=rbf;, score=0.755 total time=   0.1s\n",
      "[CV 1/5] END C=1000.0, gamma=0.1, kernel=sigmoid;, score=0.729 total time=   0.0s\n",
      "[CV 2/5] END C=1000.0, gamma=0.1, kernel=sigmoid;, score=0.720 total time=   0.0s\n",
      "[CV 3/5] END C=1000.0, gamma=0.1, kernel=sigmoid;, score=0.745 total time=   0.0s\n",
      "[CV 4/5] END C=1000.0, gamma=0.1, kernel=sigmoid;, score=0.604 total time=   0.0s\n",
      "[CV 5/5] END C=1000.0, gamma=0.1, kernel=sigmoid;, score=0.764 total time=   0.0s\n",
      "[CV 1/5] END C=1000.0, gamma=1.0, kernel=linear;, score=0.766 total time=   0.4s\n",
      "[CV 2/5] END C=1000.0, gamma=1.0, kernel=linear;, score=0.757 total time=   0.6s\n",
      "[CV 3/5] END C=1000.0, gamma=1.0, kernel=linear;, score=0.783 total time=   0.5s\n",
      "[CV 4/5] END C=1000.0, gamma=1.0, kernel=linear;, score=0.745 total time=   0.4s\n",
      "[CV 5/5] END C=1000.0, gamma=1.0, kernel=linear;, score=0.745 total time=   0.8s\n",
      "[CV 1/5] END ...C=1000.0, gamma=1.0, kernel=rbf;, score=0.766 total time=   0.0s\n",
      "[CV 2/5] END ...C=1000.0, gamma=1.0, kernel=rbf;, score=0.766 total time=   0.0s\n",
      "[CV 3/5] END ...C=1000.0, gamma=1.0, kernel=rbf;, score=0.689 total time=   0.0s\n",
      "[CV 4/5] END ...C=1000.0, gamma=1.0, kernel=rbf;, score=0.679 total time=   0.0s\n",
      "[CV 5/5] END ...C=1000.0, gamma=1.0, kernel=rbf;, score=0.698 total time=   0.0s\n",
      "[CV 1/5] END C=1000.0, gamma=1.0, kernel=sigmoid;, score=0.626 total time=   0.0s\n",
      "[CV 2/5] END C=1000.0, gamma=1.0, kernel=sigmoid;, score=0.607 total time=   0.0s\n",
      "[CV 3/5] END C=1000.0, gamma=1.0, kernel=sigmoid;, score=0.566 total time=   0.0s\n",
      "[CV 4/5] END C=1000.0, gamma=1.0, kernel=sigmoid;, score=0.528 total time=   0.0s\n",
      "[CV 5/5] END C=1000.0, gamma=1.0, kernel=sigmoid;, score=0.566 total time=   0.0s\n",
      "[CV 1/5] END C=1000.0, gamma=10.0, kernel=linear;, score=0.766 total time=   0.4s\n",
      "[CV 2/5] END C=1000.0, gamma=10.0, kernel=linear;, score=0.757 total time=   0.6s\n",
      "[CV 3/5] END C=1000.0, gamma=10.0, kernel=linear;, score=0.783 total time=   0.5s\n",
      "[CV 4/5] END C=1000.0, gamma=10.0, kernel=linear;, score=0.745 total time=   0.4s\n",
      "[CV 5/5] END C=1000.0, gamma=10.0, kernel=linear;, score=0.745 total time=   0.8s\n",
      "[CV 1/5] END ..C=1000.0, gamma=10.0, kernel=rbf;, score=0.757 total time=   0.0s\n",
      "[CV 2/5] END ..C=1000.0, gamma=10.0, kernel=rbf;, score=0.710 total time=   0.0s\n",
      "[CV 3/5] END ..C=1000.0, gamma=10.0, kernel=rbf;, score=0.717 total time=   0.0s\n",
      "[CV 4/5] END ..C=1000.0, gamma=10.0, kernel=rbf;, score=0.670 total time=   0.0s\n",
      "[CV 5/5] END ..C=1000.0, gamma=10.0, kernel=rbf;, score=0.689 total time=   0.0s\n",
      "[CV 1/5] END C=1000.0, gamma=10.0, kernel=sigmoid;, score=0.533 total time=   0.0s\n",
      "[CV 2/5] END C=1000.0, gamma=10.0, kernel=sigmoid;, score=0.579 total time=   0.0s\n",
      "[CV 3/5] END C=1000.0, gamma=10.0, kernel=sigmoid;, score=0.538 total time=   0.0s\n",
      "[CV 4/5] END C=1000.0, gamma=10.0, kernel=sigmoid;, score=0.557 total time=   0.0s\n",
      "[CV 5/5] END C=1000.0, gamma=10.0, kernel=sigmoid;, score=0.604 total time=   0.0s\n",
      "Best Parameters: {'C': 100.0, 'gamma': 0.1, 'kernel': 'rbf'}\n"
     ]
    }
   ],
   "source": [
    "# Put your code here\n",
    "param_grid = {'C': [0.1, 1.0, 10.0, 100.0, 1000.0],\n",
    "              'gamma': [0.01, 0.1, 1.0, 10.0],\n",
    "              'kernel': ['linear', 'rbf', 'sigmoid']}\n",
    "\n",
    "grid = GridSearchCV(SVC(), param_grid, refit = True, verbose = 3, cv = 5)\n",
    "\n",
    "# Fitting the model for grid search\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "# Printing the best parameters found by GridSearchCV\n",
    "print(\"Best Parameters:\", grid.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&#9989; **Question 4.1 (1 point):** How do the \"best params\" results of the grid search compare to what you used in Part 3? Did the hyper parameter(s) change? What kernel did the grid search determine was the best option? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=+3>&#9998;</font> In part 3, we used {C=10.0, kernel='sigmoid'}. In this part, the best fit parameters are {'C': 100.0, 'gamma': 0.1, 'kernel': 'rbf'}. This part includes a gamma value of 0.1, which we did not see in the first model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Evaluating the best fit model\n",
    "\n",
    "Now that we have found the \"best params\", let's determine how good the fit is.\n",
    "\n",
    "**&#9989; Task 4.2 (2 points):** Use the test features to predict the outcomes for the best model. Evaluate the fit using the **confusion matrix** and **classification report**.\n",
    "\n",
    "**Note:** Double-check the documentation on the confusion matrix because the way `sklearn` outputs false positives and false negatives may be different from what most images on the web indicate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC(C=100.0, gamma=0.1, random_state=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(C=100.0, gamma=0.1, random_state=1)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "SVC(C=100.0, gamma=0.1, random_state=1)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Put your code here\n",
    "bf_model = SVC(kernel = 'rbf', C = 100.0, gamma = 0.1, random_state = 1)\n",
    "bf_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[66, 10],\n",
       "       [21, 37]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#confusion matrix\n",
    "bf_y_pred = bf_model.predict(X_test)\n",
    "bf_conf_matrix = confusion_matrix(y_test, bf_y_pred)\n",
    "print(\"Confusion Matrix:\")\n",
    "bf_conf_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.87      0.81        76\n",
      "           1       0.79      0.64      0.70        58\n",
      "\n",
      "    accuracy                           0.77       134\n",
      "   macro avg       0.77      0.75      0.76       134\n",
      "weighted avg       0.77      0.77      0.76       134\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#class report\n",
    "bf_report = classification_report(y_test, bf_y_pred)\n",
    "print(\"Classification Report:\")\n",
    "print(bf_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&#9989; **Question 4.2 (1 point):** How accurate is this \"best\" model? What evidence are you using to determine that? How many false positives and false negatives does it predict?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=+3>&#9998;</font> While it is better than the first model, it is still quite inaccurate with a weighted average precision score of 77%. It has 10 false positives and 21 false negatives."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### &#128721; STOP\n",
    "**Pause to commit your changes to your Git repository!**\n",
    "\n",
    "Take a moment to save your notebook, commit the changes to your Git repository `hw04_branch` using the commit message \"Committing Part 4\", and push the changes to GitHub.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 5. Using Principal Components (10 points)\n",
    "\n",
    "The full model uses all 6 features to predict the results and you likely found that the model is decently accurate using all 6 features, but not perfect. **Could we get the same level of accuracy (or better) using fewer features?** When datasets start to get very large and complex, applying some sort of **feature reduction** method can reduce the computational resources needed to train the model and, in some case actually improve the accuracy.\n",
    "\n",
    "When performing feature reduction, one could simply try to identify which features seem most important and drop the ones that aren't, but performing a Principal Component Analysis (PCA) to determine the features that contribute the most to the model (through their accounted variance) can be more effective."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 Running a Principle Component Analysis (PCA)\n",
    "\n",
    "Since we have 6 total features to start with, let's see how well we can do if only use 1/3 as many features. Reduce the feature count to **2** principle components. We'll see how well we can predict the classes of the credit card approval dataset with just **2 features**!\n",
    "\n",
    "**&#9989; Task 5.1 (3 points):**  Using `PCA()` and the associated `fit()` method, run a principle component analysis on your training features using 2 components. Transform both the test and training features using the result of your PCA. Print the `explained_variance_ratio_`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explained Variance Ratio: [0.33546894 0.1830097 ]\n"
     ]
    }
   ],
   "source": [
    "# Put your code here\n",
    "pca = PCA(n_components = 2)\n",
    "pca.fit(X_train)\n",
    "\n",
    "X_train_pca = pca.transform(X_train)\n",
    "X_test_pca = pca.transform(X_test)\n",
    "\n",
    "print(\"Explained Variance Ratio:\", pca.explained_variance_ratio_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&#9989; **Question 5.1 (1 point):** What is the total explained variance ratio captured by this simple 2-component PCA? (e.g. sum up the explained variance from all 2 components) How well do you think a model with this many feature will perform? Why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=+3>&#9998;</font> A model with this many features will not perform very well because only 0.335 and 0.183 of the variance is explained by the model. Combined this is still around 50% of the variance, and this could be improved by potentially adding more features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Fit and Evaluate an SVC model\n",
    "\n",
    "Using the PCA transformed features, we need to train and test a new SVC model. You'll want to perform the `GridSearchCV` again since there may a better choice for the kernel and the hyper-parameters.\n",
    "\n",
    "**&#9989; Task 5.2 (2 points):**  Using the PCA transformed training data, build and train an SVC model using the `GridSearchCV` tool to make sure you're using the best kernel and hyper-parameter combination. Predict the classes using the PCA transformed test data. Evaluate the model using the classification report, and the confusion matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 24 candidates, totalling 72 fits\n",
      "[CV] END ..................C=0.1, gamma=scale, kernel=linear; total time=   0.0s\n",
      "[CV] END ..................C=0.1, gamma=scale, kernel=linear; total time=   0.0s\n",
      "[CV] END ..................C=0.1, gamma=scale, kernel=linear; total time=   0.0s\n",
      "[CV] END .....................C=0.1, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END .....................C=0.1, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END .....................C=0.1, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END .................C=0.1, gamma=scale, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END .................C=0.1, gamma=scale, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END .................C=0.1, gamma=scale, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ...................C=0.1, gamma=auto, kernel=linear; total time=   0.0s\n",
      "[CV] END ...................C=0.1, gamma=auto, kernel=linear; total time=   0.0s\n",
      "[CV] END ...................C=0.1, gamma=auto, kernel=linear; total time=   0.0s\n",
      "[CV] END ......................C=0.1, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END ......................C=0.1, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END ......................C=0.1, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END ..................C=0.1, gamma=auto, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ..................C=0.1, gamma=auto, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ..................C=0.1, gamma=auto, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ....................C=1, gamma=scale, kernel=linear; total time=   0.0s\n",
      "[CV] END ....................C=1, gamma=scale, kernel=linear; total time=   0.0s\n",
      "[CV] END ....................C=1, gamma=scale, kernel=linear; total time=   0.0s\n",
      "[CV] END .......................C=1, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END .......................C=1, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END .......................C=1, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END ...................C=1, gamma=scale, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ...................C=1, gamma=scale, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ...................C=1, gamma=scale, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END .....................C=1, gamma=auto, kernel=linear; total time=   0.0s\n",
      "[CV] END .....................C=1, gamma=auto, kernel=linear; total time=   0.0s\n",
      "[CV] END .....................C=1, gamma=auto, kernel=linear; total time=   0.0s\n",
      "[CV] END ........................C=1, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END ........................C=1, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END ........................C=1, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END ....................C=1, gamma=auto, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ....................C=1, gamma=auto, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ....................C=1, gamma=auto, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ...................C=10, gamma=scale, kernel=linear; total time=   0.0s\n",
      "[CV] END ...................C=10, gamma=scale, kernel=linear; total time=   0.0s\n",
      "[CV] END ...................C=10, gamma=scale, kernel=linear; total time=   0.0s\n",
      "[CV] END ......................C=10, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END ......................C=10, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END ......................C=10, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END ..................C=10, gamma=scale, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ..................C=10, gamma=scale, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ..................C=10, gamma=scale, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ....................C=10, gamma=auto, kernel=linear; total time=   0.0s\n",
      "[CV] END ....................C=10, gamma=auto, kernel=linear; total time=   0.0s\n",
      "[CV] END ....................C=10, gamma=auto, kernel=linear; total time=   0.0s\n",
      "[CV] END .......................C=10, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END .......................C=10, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END .......................C=10, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END ...................C=10, gamma=auto, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ...................C=10, gamma=auto, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ...................C=10, gamma=auto, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ..................C=100, gamma=scale, kernel=linear; total time=   0.0s\n",
      "[CV] END ..................C=100, gamma=scale, kernel=linear; total time=   0.0s\n",
      "[CV] END ..................C=100, gamma=scale, kernel=linear; total time=   0.0s\n",
      "[CV] END .....................C=100, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END .....................C=100, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END .....................C=100, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END .................C=100, gamma=scale, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END .................C=100, gamma=scale, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END .................C=100, gamma=scale, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ...................C=100, gamma=auto, kernel=linear; total time=   0.0s\n",
      "[CV] END ...................C=100, gamma=auto, kernel=linear; total time=   0.0s\n",
      "[CV] END ...................C=100, gamma=auto, kernel=linear; total time=   0.0s\n",
      "[CV] END ......................C=100, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END ......................C=100, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END ......................C=100, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END ..................C=100, gamma=auto, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ..................C=100, gamma=auto, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ..................C=100, gamma=auto, kernel=sigmoid; total time=   0.0s\n",
      "Best Parameters: {'C': 10, 'gamma': 'auto', 'kernel': 'rbf'}\n"
     ]
    }
   ],
   "source": [
    "# Put your code here\n",
    "param_grid = {\n",
    "    'C': [0.1, 1, 10, 100],\n",
    "    'gamma': ['scale', 'auto'],\n",
    "    'kernel': ['linear', 'rbf', 'sigmoid']\n",
    "}\n",
    "\n",
    "grid = GridSearchCV(SVC(), param_grid, refit = True, verbose = 2, cv = 3)\n",
    "grid.fit(X_train_pca, y_train)\n",
    "\n",
    "print(\"Best Parameters:\", grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predictions\n",
    "y_pred = grid.predict(X_test_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.78      0.76        76\n",
      "           1       0.69      0.66      0.67        58\n",
      "\n",
      "    accuracy                           0.72       134\n",
      "   macro avg       0.72      0.72      0.72       134\n",
      "weighted avg       0.72      0.72      0.72       134\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#class report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[59 17]\n",
      " [20 38]]\n"
     ]
    }
   ],
   "source": [
    "#confusion matrix\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&#9989; **Question 5.2 (1 point):** How accurate is this model? What evidence are you using to determine that? How many false positives and false negatives does it predict? How does it compare to the full feature model?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=+3>&#9998;</font> This appears to be worse than the full feature model, with a weighted average precision score of 72%. It predicts 17 false positives and 20 false negatives."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 Repeat your analysis with more components\n",
    "\n",
    "You probably found that the model with 2 features didn't actually do too bad, which is great given how few features we're using, but it's still not as good as just using all of the feature. Can we do better?\n",
    "\n",
    "What if we increase the number of principle components to **4** (2/3 of the original feature count)? What happens now?\n",
    "\n",
    "**&#9989; Task 5.3 (2 points):** Repeat your analysis from 5.1 and 5.2 using **4 components** instead. As part of your analysis, **print the total explained variance ratio for both components as well as the sum of these values**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 24 candidates, totalling 72 fits\n",
      "[CV] END ..................C=0.1, gamma=scale, kernel=linear; total time=   0.0s\n",
      "[CV] END ..................C=0.1, gamma=scale, kernel=linear; total time=   0.0s\n",
      "[CV] END ..................C=0.1, gamma=scale, kernel=linear; total time=   0.0s\n",
      "[CV] END .....................C=0.1, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END .....................C=0.1, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END .....................C=0.1, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END .................C=0.1, gamma=scale, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END .................C=0.1, gamma=scale, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END .................C=0.1, gamma=scale, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ...................C=0.1, gamma=auto, kernel=linear; total time=   0.0s\n",
      "[CV] END ...................C=0.1, gamma=auto, kernel=linear; total time=   0.0s\n",
      "[CV] END ...................C=0.1, gamma=auto, kernel=linear; total time=   0.0s\n",
      "[CV] END ......................C=0.1, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END ......................C=0.1, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END ......................C=0.1, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END ..................C=0.1, gamma=auto, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ..................C=0.1, gamma=auto, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ..................C=0.1, gamma=auto, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ....................C=1, gamma=scale, kernel=linear; total time=   0.0s\n",
      "[CV] END ....................C=1, gamma=scale, kernel=linear; total time=   0.0s\n",
      "[CV] END ....................C=1, gamma=scale, kernel=linear; total time=   0.0s\n",
      "[CV] END .......................C=1, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END .......................C=1, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END .......................C=1, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END ...................C=1, gamma=scale, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ...................C=1, gamma=scale, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ...................C=1, gamma=scale, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END .....................C=1, gamma=auto, kernel=linear; total time=   0.0s\n",
      "[CV] END .....................C=1, gamma=auto, kernel=linear; total time=   0.0s\n",
      "[CV] END .....................C=1, gamma=auto, kernel=linear; total time=   0.0s\n",
      "[CV] END ........................C=1, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END ........................C=1, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END ........................C=1, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END ....................C=1, gamma=auto, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ....................C=1, gamma=auto, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ....................C=1, gamma=auto, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ...................C=10, gamma=scale, kernel=linear; total time=   0.0s\n",
      "[CV] END ...................C=10, gamma=scale, kernel=linear; total time=   0.0s\n",
      "[CV] END ...................C=10, gamma=scale, kernel=linear; total time=   0.0s\n",
      "[CV] END ......................C=10, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END ......................C=10, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END ......................C=10, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END ..................C=10, gamma=scale, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ..................C=10, gamma=scale, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ..................C=10, gamma=scale, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ....................C=10, gamma=auto, kernel=linear; total time=   0.0s\n",
      "[CV] END ....................C=10, gamma=auto, kernel=linear; total time=   0.0s\n",
      "[CV] END ....................C=10, gamma=auto, kernel=linear; total time=   0.0s\n",
      "[CV] END .......................C=10, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END .......................C=10, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END .......................C=10, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END ...................C=10, gamma=auto, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ...................C=10, gamma=auto, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ...................C=10, gamma=auto, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ..................C=100, gamma=scale, kernel=linear; total time=   0.0s\n",
      "[CV] END ..................C=100, gamma=scale, kernel=linear; total time=   0.0s\n",
      "[CV] END ..................C=100, gamma=scale, kernel=linear; total time=   0.0s\n",
      "[CV] END .....................C=100, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END .....................C=100, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END .....................C=100, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END .................C=100, gamma=scale, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END .................C=100, gamma=scale, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END .................C=100, gamma=scale, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ...................C=100, gamma=auto, kernel=linear; total time=   0.0s\n",
      "[CV] END ...................C=100, gamma=auto, kernel=linear; total time=   0.0s\n",
      "[CV] END ...................C=100, gamma=auto, kernel=linear; total time=   0.0s\n",
      "[CV] END ......................C=100, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END ......................C=100, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END ......................C=100, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END ..................C=100, gamma=auto, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ..................C=100, gamma=auto, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ..................C=100, gamma=auto, kernel=sigmoid; total time=   0.0s\n",
      "Explained Variance Ratios per Component: [0.33546894 0.1830097  0.15763395 0.13927241]\n",
      "Sum of Explained Variance Ratios: 0.8153850044810061\n",
      "Best Parameters: {'C': 1, 'gamma': 'auto', 'kernel': 'rbf'}\n"
     ]
    }
   ],
   "source": [
    "# Put your code here\n",
    "pca = PCA(n_components = 4)\n",
    "four_X_train_pca = pca.fit_transform(X_train)\n",
    "four_X_test_pca = pca.transform(X_test)\n",
    "\n",
    "#grid search\n",
    "param_grid = {\n",
    "    'C': [0.1, 1, 10, 100],\n",
    "    'gamma': ['scale', 'auto'],\n",
    "    'kernel': ['linear', 'rbf', 'sigmoid']\n",
    "}\n",
    "\n",
    "grid = GridSearchCV(SVC(), param_grid, refit = True, verbose = 2, cv = 3)\n",
    "grid.fit(four_X_train_pca, y_train)\n",
    "\n",
    "print(\"Explained Variance Ratios per Component:\", pca.explained_variance_ratio_)\n",
    "print(\"Sum of Explained Variance Ratios:\", np.sum(pca.explained_variance_ratio_))\n",
    "print(\"Best Parameters:\", grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.91      0.80        76\n",
      "           1       0.82      0.53      0.65        58\n",
      "\n",
      "    accuracy                           0.75       134\n",
      "   macro avg       0.77      0.72      0.72       134\n",
      "weighted avg       0.76      0.75      0.73       134\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#class report\n",
    "y_pred = grid.predict(four_X_test_pca) #predicted vals\n",
    "\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[69  7]\n",
      " [27 31]]\n"
     ]
    }
   ],
   "source": [
    "#confusion matrix\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&#9989; **Question 5.3 (1 point):** What is the total explained variance ratio captured by this PCA? How accurate is this model? What evidence are you using to determine that? How many false positives and false negatives does it predict? How does it compare to the 2 PCA component model? To the full feature model?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=+3>&#9998;</font> The total explained variance ratio is 0.815, making this model more accurate than the 2-feature model. It predicts 7 false positives and 27 false negatives. It is better than all of the previous models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### &#128721; STOP\n",
    "**Pause to commit your changes to your Git repository!**\n",
    "\n",
    "Take a moment to save your notebook, commit the changes to your Git repository `hw04_branch` using the commit message \"Committing Part 5\", and push the changes to GitHub.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 6. How well does PCA work? (14 points)\n",
    "\n",
    "Clearly, the number of components we use in our PCA matters. Let's investigate how they matter by systematically building a model for any number of selected components. While this might seem a bit unnecessary for such a relatively small dataset, **this can be very useful for more complex datasets and models!**\n",
    "\n",
    "### 6.1 Accuracy vs. Components\n",
    "\n",
    "To systematically explore how well PCA improves our classification model, we will do this by writing a function that creates the PCA, the SVC model, fits the training data, predict the labels using test data, and returns the accuracy scores and the explained variance ratio. So your function will take as input:\n",
    "* the number of requested PCA components\n",
    "* the training feature data\n",
    "* the testing feature data\n",
    "* the training data labels\n",
    "* the test data labels\n",
    "\n",
    "and it should **return** the accuracy score for an SVC model fit to pca transformed features and the **total** explained variance ratio (i.e. the sum of the explained variance for each component).\n",
    "\n",
    "**&#9989; Task 6.1 (4 points):** Create this function, which you will use in the next section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put your code here\n",
    "def evaluate(n_components, X_train, X_test, y_train, y_test):\n",
    "    #pca\n",
    "    pca = PCA(n_components = n_components)\n",
    "    X_train_pca = pca.fit_transform(X_train)\n",
    "    X_test_pca = pca.transform(X_test)\n",
    "    #svc\n",
    "    model = SVC()\n",
    "    model.fit(X_train_pca, y_train)\n",
    "    #pred\n",
    "    eval_y_pred = model.predict(X_test_pca)\n",
    "    #accuracy/variance\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    total_explained_variance = sum(pca.explained_variance_ratio_)\n",
    "    \n",
    "    return accuracy, total_explained_variance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2 Compute accuracies\n",
    "\n",
    "Now that you have created a function that returns the accuracy for a given number of components, we will use that to plot the how the accuracy of your SVC model changes when we increase the number of components used in the PCA.\n",
    "\n",
    "**&#9989; Task 6.2 (2 points):** Going from **1 to 6** components, use your function above to compute and store (as a list) the accuracy of your models and the total explained variance ratio of your models.\n",
    "\n",
    "**Note**: you'll be running many grid searches to do this, so it might take your computer a bit of time to run all of these models. Please be patient. It shouldn't more than a couple minutes!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Component(s): 1 Accuracy: 0.7463 Explained Variance: 0.3355\n",
      "Component(s): 2 Accuracy: 0.7463 Explained Variance: 0.5185\n",
      "Component(s): 3 Accuracy: 0.7463 Explained Variance: 0.6761\n",
      "Component(s): 4 Accuracy: 0.7463 Explained Variance: 0.8154\n",
      "Component(s): 5 Accuracy: 0.7463 Explained Variance: 0.9132\n",
      "Component(s): 6 Accuracy: 0.7463 Explained Variance: 1.0000\n"
     ]
    }
   ],
   "source": [
    "# Put your code here\n",
    "accuracy_scores = []\n",
    "variance_ratios = []\n",
    "\n",
    "for n_components in range(1, 7):\n",
    "    accuracy, explained_variance = evaluate(n_components, X_train, X_test, y_train, y_test)\n",
    "    accuracy_scores.append(accuracy)\n",
    "    variance_ratios.append(explained_variance)\n",
    "    print(f'Component(s): {n_components} Accuracy: {accuracy:.4f} Explained Variance: {explained_variance:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I can'f figure out what is wrong with my loop, it is returning the same accuracy score which is obviously incorrect."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.3 Plot accuracy vs number of components\n",
    "\n",
    "Now that we have those numbers, it makes sense to look at the accuracy vs # of components.\n",
    "\n",
    "**&#9989; Task 6.3 (2 points):** Plot the accuracy vs # of components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Put your code here\n",
    "plt.plot(range(1, 7), accuracy_scores, marker = 'o', linestyle = '-', color = 'lightblue')\n",
    "plt.title('SVC Accuracy vs. Number of Components')\n",
    "plt.xlabel('Number of PCA Components')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xticks(range(1, 7))\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**&#9989; Question 6.1 (3 point):** What do you observe about the accuracy as a function of the number of PCA components you use? One goal of using dimension reduction strategies is to develop a model with the fewest features while maximizing the accuracy. Given that motivation, what number of principal components would you choose and why?  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=+3>&#9998;</font> From the variance outputs, I can tell that 6 components is the most accurate because it is in the 90% range. That would be my choice based on the variance, but having the real accuracy scores would be helpful."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.4 Plot total explained variance vs number of components\n",
    "\n",
    "What if we look at total explained variance as a function of # of components?\n",
    "\n",
    "**&#9989; Task 6.4 (2 points):** Plot the total explained variance ratio vs # of components. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Put your code here\n",
    "plt.plot(range(1, 7), variance_ratios, marker = 'o', linestyle = '-', color = 'lightgreen')\n",
    "plt.title('Total Explained Variance Ratio vs. Number of Components')\n",
    "plt.xlabel('Number of PCA Components')\n",
    "plt.ylabel('Total Explained Variance Ratio')\n",
    "plt.xticks(range(1, 7))\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**&#9989; Question 6.2 (1 points):** Based on your answer from question 6.1 and the plot above, what is the explained variance for the number of principal components that you chose?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=+3>&#9998;</font> 100% is the explained variance for 6 components."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### &#128721; STOP\n",
    "**Pause to commit your changes to your Git repository!**\n",
    "\n",
    "Take a moment to save your notebook, commit the changes to your Git repository `hw04_branch` using the commit message \"Committing Part 6\", and push the changes to GitHub.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 7. Revisiting the Perceptron classifier (10 points)\n",
    "\n",
    "In class you implemented your own perceptron class. Fortunately, there is a perceptron classifier already built into scikit learn, so in this portion of the assignment we will be exploring scikit learn's perceptron\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&#9989; **Do this**: \n",
    "Run the following cell to import the code from the Perceptron class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Perceptron"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**&#9989; Task 7.1 (4 points):** Create an instance of the `Perceptron` object using **alpha=0.01** and **penalty='l2'**. Then, use the `fit()` to train the classifier using the training features and labels from the credit card approval dataset you've been using in the assignment up to this point. Finally, use the `predict()` method to predict the labels for the test features and print the accuracy score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.62\n"
     ]
    }
   ],
   "source": [
    "# Put your code here\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "#creating object\n",
    "perceptron = Perceptron(penalty = 'l2', alpha = 0.01)\n",
    "\n",
    "# fitting\n",
    "perceptron.fit(X_train_scaled, y_train)\n",
    "\n",
    "#testing\n",
    "y_pred = perceptron.predict(X_test_scaled)\n",
    "\n",
    "#accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy: {accuracy:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**&#9989; Question 7.1 (1 points):** How well of job did the Perceptron classifier do on the credit card approval dataset? How does it compare to the SVC model you built in the previous parts of this assignment?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=+3>&#9998;</font> It has an accuracy score of 62% which is worse than the previous SVC models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**&#9989; Task 7.2 (4 points):** Now perform a grid search as you did with the support vector classifier earlier in this assignment. Here you will want to search over `penalty` = `l2`, `l1`, `elasticnet` and `alpha`= `0.0001`, `0.001`, `0.01`, and `0.1`. Find and return the best parameters, the confusion matrix, and the classification report. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {color: black;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5, estimator=Perceptron(alpha=0.01, penalty=&#x27;l2&#x27;),\n",
       "             param_grid={&#x27;alpha&#x27;: [0.0001, 0.001, 0.01, 0.1],\n",
       "                         &#x27;penalty&#x27;: [&#x27;l2&#x27;, &#x27;l1&#x27;, &#x27;elasticnet&#x27;]},\n",
       "             scoring=&#x27;accuracy&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=5, estimator=Perceptron(alpha=0.01, penalty=&#x27;l2&#x27;),\n",
       "             param_grid={&#x27;alpha&#x27;: [0.0001, 0.001, 0.01, 0.1],\n",
       "                         &#x27;penalty&#x27;: [&#x27;l2&#x27;, &#x27;l1&#x27;, &#x27;elasticnet&#x27;]},\n",
       "             scoring=&#x27;accuracy&#x27;)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: Perceptron</label><div class=\"sk-toggleable__content\"><pre>Perceptron(alpha=0.01, penalty=&#x27;l2&#x27;)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Perceptron</label><div class=\"sk-toggleable__content\"><pre>Perceptron(alpha=0.01, penalty=&#x27;l2&#x27;)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=5, estimator=Perceptron(alpha=0.01, penalty='l2'),\n",
       "             param_grid={'alpha': [0.0001, 0.001, 0.01, 0.1],\n",
       "                         'penalty': ['l2', 'l1', 'elasticnet']},\n",
       "             scoring='accuracy')"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Put your code here\n",
    "bf_perceptron = Perceptron()\n",
    "\n",
    "#grid\n",
    "param_grid = {\n",
    "    'penalty': ['l2', 'l1', 'elasticnet'],\n",
    "    'alpha': [0.0001, 0.001, 0.01, 0.1]\n",
    "}\n",
    "\n",
    "#search\n",
    "grid_search = GridSearchCV(estimator=perceptron, param_grid = param_grid, scoring = 'accuracy', cv = 5)\n",
    "\n",
    "#training\n",
    "grid_search.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'alpha': 0.001, 'penalty': 'elasticnet'}\n"
     ]
    }
   ],
   "source": [
    "print(\"Best parameters:\", grid_search.best_params_)\n",
    "\n",
    "best_perceptron = grid_search.best_estimator_\n",
    "y_pred = best_perceptron.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.76      0.72        76\n",
      "           1       0.62      0.52      0.57        58\n",
      "\n",
      "    accuracy                           0.66       134\n",
      "   macro avg       0.65      0.64      0.64       134\n",
      "weighted avg       0.65      0.66      0.65       134\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#class report\n",
    "report = classification_report(y_test, y_pred)\n",
    "print(\"Classification Report:\\n\", report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      " [[58 18]\n",
      " [28 30]]\n"
     ]
    }
   ],
   "source": [
    "#confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(\"Confusion Matrix:\\n\", cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**&#9989; Question 7.2 (1 point):** How do these results compare to the results when using a support vector classifier now that we optimized the parameters? Did the perceptron do better or worse? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=+3>&#9998;</font> The perceptron did worse than the SVC, it had a lower weighted average precision score of .65."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### &#128721; STOP\n",
    "**Pause to commit your changes to your Git repository!**\n",
    "\n",
    "Take a moment to save your notebook, commit the changes to your Git repository `hw04_branch` using the commit message \"Committing Part 7\", and push the changes to GitHub.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 1. Continued\n",
    "\n",
    "Now that you've finished your new \"development\" on your 202 turn-in repo, you can merge your work back into your `main` branch.\n",
    "\n",
    "**&#9989; Do the following**:\n",
    "\n",
    "7. Switch back to your `main` branch. \n",
    "8. Merge your `hw04_branch` with your `main` branch. \n",
    "9. Finally, push the changes to GitHub."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Assignment wrap-up¶\n",
    "Please fill out the form that appears when you run the code below. **You must completely fill this out in order to receive credit for the assignment!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<iframe \n",
       "\tsrc=\"https://forms.office.com/r/jZyy65R83k\" \n",
       "\twidth=\"800px\" \n",
       "\theight=\"600px\" \n",
       "\tframeborder=\"0\" \n",
       "\tmarginheight=\"0\" \n",
       "\tmarginwidth=\"0\">\n",
       "\tLoading...\n",
       "</iframe>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import HTML\n",
    "HTML(\n",
    "\"\"\"\n",
    "<iframe \n",
    "\tsrc=\"https://forms.office.com/r/jZyy65R83k\" \n",
    "\twidth=\"800px\" \n",
    "\theight=\"600px\" \n",
    "\tframeborder=\"0\" \n",
    "\tmarginheight=\"0\" \n",
    "\tmarginwidth=\"0\">\n",
    "\tLoading...\n",
    "</iframe>\n",
    "\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Congratulations, you're done!\n",
    "Submit this assignment by uploading it to the course Desire2Learn web page. Go to the \"Homework Assignments\" folder, find the submission folder for Homework 4, and upload your notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&#169; Copyright 2024,  Department of Computational Mathematics, Science and Engineering at Michigan State University"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
